





## **1：引言**

熟悉人工智能发展史的同学应该都知道现在很火的机器学习、深度学习并非人工智能的全部，还经常见到人工智能流派或学派的说法。

### 流派@学派

一种说法是分**信息计算**学派和**神经网络**学派。

还一种说法是分**统计学习**学派（就是现在的普遍了解的机器学习中的大部分内容，李航老师的《统计学习方法》一书也是这领域的经典著作，书名也揭露了本质）、

**连接主义或神经网络**学派（重新焕发青春后就是目前火爆的深度学习了，尤其在cv领域的广泛应用使得很多人又跳过了机器学习的内容直接研究深度学习理论了)、

**行为主义**（这个流派强调Agent的控制，自适应与自动进化，这个方向一直没有大火，以后在机器人及物联网，甚至自动驾驶技术发展后，每个agent拥有自我智能时可能会火，但估计那时人会害怕的了）、

另外一个就是**符号主义**，是我们主要讲的。



符号主义，或信息计算学派十分看重程序的**逻辑结构，符号操作**以及**计算能力**，希望用机器证明的方式去**证明或推理知识**，知识的表示和推理（KPR:Knowledge Representation and  Reasoning）也构成了符号派的核心内容。在这套理论的指导下，1960-1970年代诞生了很多**专家系统**，如医学专家系统，系统中通过录入大量症状，症状的**依赖关系**，症状与疾病的**关系及相应推理规则**，用**符号演算**，逻辑推理的方式告诉你可能的疾病及诊断**思路**。

笔者在02年选择研究方向时也读了图书馆很多逻辑推理，符号计算的书，报考了数理逻辑的研究方向，无奈真正读研时想这得**要求所有的推理规则及知识要全**才行，即用现在正规的说法，**程序性知识要充足，陈述性知识也要充足**才能进行良好的推理，而当年很难想象怎么凑齐这两类知识，没这两类知识就完备不了啊。当时有点这想法，当然最主要的还是目光不够长远看不到没弄明白逻辑主义的未来，最终改选择了图论方向，尽管好多年并没直接用到其相关理论--扯远了。

到了1977年，Feigenbaum提出了**知识工程**的概念，其知识库中包括了**某种特定领域的专业技能**，  他和这些特定领域的专家合作，将他们的专家经验和知识存入知识库，然后通过一种被称作推理机的程序对用户的问题进行推理解答。

尽管有如此成就，到了70年代随着逻辑主义长期没有突破，而**连接主义(就是神经网络)**随着BP网络的提出迎来了一波发展，逻辑主义便沉寂了，一些经典的定理证明，逻辑程序语言的发明，及产生式专家系统的诞生都是在逻辑主义盛行的这个时期。此阶段的产生式专家系统由一个知识库，一组产生式规则和一个控制系统组成，控制系统主要包括了规则的表达，规则生成，谓词演算，知识获取，知识推理等...读到这里接触过知识图谱的人肯定会想这不就是知识图谱里面本体推理那一套么，是的，至少我是这么认为的。





人工智能发展了这么多年，在符号派这块逐步诞生了**语义网络(Semantic  Network,1960)**，**知识表示，本体论，语义网（Semantic  Web），自然语言处理**等一系列成就，语义网是传统人工智能与Web融合的结果，是**符号主义核心知识表示与推理在现代Web中的应用**，其中的RDF/OWL都是面向Web的知识表示语言。于是随着互联网及大数据诞生的知识图谱的一种定义便是：

**知识图谱就是大规模语义网。**

知识图谱与以前的专家系统时代的知识工程的不同也正体现在这大规模上，***专家系统时代需要专家手工获取知识*，**但现在就连行业知识图谱的构建也不能紧靠人工去构建了。知识图谱**对规模性的渴求**主要**源于知识完备性的理论**，即要包含能解决问题所依赖的所有知识，及知识的知识，这个当然是无穷了。

现在的机器学习，深度学习实用性的提高，主要得益于**当前大数据的获取相对容易**和**计算能力的提升**，但想想我们教一个从没见过猫和老虎的小朋友说这是猫，这是虎，小朋友马上就认识了猫和虎，给他个简笔画也能马上认出，从来不需要拿成千上万张图片视频观看之后才认识。目前家家人工智能企业都在做计算机视觉，人脸识别，而这归根结底只能算是感知层的技术，一个完整的人工智能系统在感知层之上还要构建认知能力，离开了知识的人工智能就像婴儿一样，虽然有聪明的脑袋，但不能称之为智慧。

人工智能的**研究领域**包括**认知建模、知识表示、推理及应用、机器感知、机器思维、机器学习、机器行为和智能系统等**，其研究目标即**提升智能体**的推**理，知识，规划，学习，交流，感知，移动和操作物体的能力等**，这也体现了这类系统通过感知获取信息和知识，通过推理得到新知识，提升其思维和学习能力并最终通过行为与外界交互的思想。

力维智联数据与人工智能团队致力于人脸大数据，知识图谱，行人跨境追踪ReID等产品的研发，广泛应用于公共安全及社区治理等场景，其不仅涉及到人脸检测，人脸识别等基础算法的研发，还涉及与诸多多源异构数据的融合，碰撞分析，挖掘行人背后的关系及信息关联，挖掘行人之间的同行跟踪偶遇关系，对案件的信息研判，事件溯源，关系挖掘等技战法的研究。力维知识图谱通过融合人脸识别/行人识别的结果与公安及社区的多源异构动静态数据，构建人、事、地、物、组织的知识体系，并进而挖掘单个个体背后的世界，只有这样才能将信息转为解决真实问题的工具。

下面简要介绍下我们在做的产品。

**2：力维知识图谱构建**

一个完整的知识图谱系统工程包括知识图谱的构建及知识图谱的应用。知识图谱构建的核心流程包括：知识建模，知识抽取，知识融合，知识推理，知识计算等环节，知识图谱的应用则为根据具体业务场景问题而采用的不同的知识访问及展现方式。像是案件研判，一人一档，交互问答，智能搜索，语音交互，图谱可视化探索等。

![img](ML@%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0.assets/v2-d81321a09e28d2fc98bcac4e1e91edaf_720w.jpg)

我们对接的数据源主要有公安的静态数据源及动态数据源，静态数据主要是一些存量数据，包括信息系统的结构化数据，也包括一些非结构化数据。动态数据则指采集的视频，抓拍图片，警情事件等。整个软件架构的数据流向即指明了数据->信息->知识->智慧的转化过程，为人所用，为解决具体问题所用。

知识表示方面，图中我给出的是具体的实现技术了，实际在理论上是分为符号表示及向量表示，后者向量是把信息的向量化表示，涉及到一定规则的编码等，其似乎是一个新的理论研究方向，但我对其没研究不做展开。符号表示的就常规的了，可以有基于本体论理论基础的RDF/OWL系列，有基于属性图的，也有继续采用结构化数据会非结构化数据的表示方式，这个不能排除。RDF/OWL系列理论中认为知识是主谓宾三元组的陈述，OWL进一步扩充了Schema及逻辑推理能力，这类知识表示并没有关系属性和实体属性的概念及存在。属性图的知识表示中则有了这部分能力，所以在属性图中很简单的图结构在RDF中则需要很复杂的结构。

知识抽取部分我放上了概念及本体的发现，也可称之为本体建模，这个实际是对问题域中概念的抽象，即如何定义这个问题域所在的世界，存在哪些概念或类，哪些子类，哪些实体间的关系，每个实体及关系有哪些属性等，这实际即是定义数据模型，包括了类，属性，关系和词汇的集合。这个严格来说不算知识抽取的步骤，但是却是知识抽取的基础。知识抽取具体一点包括了实体抽取，关系抽取，属性抽取及规则抽取等，这个对于静态数据是比较明确的，对于动态数据来说，人脸检测之后得到的目标可以认为是实体，经人脸融合之后进一步跟底库比对得到这是谁后也可以作为一个实体，抽取到哪一个层次要看解决的问题是什么。关系抽取比如监控视频中的同行人等。

知识融合阶段需要对从多源异构数据源中抽取的各类动静态数据进行融合，融合时要对各种地址，描述不一的情形，对同一人多次抓拍的情形进行融合消岐合并处理。

知识存储则涉及知识的落盘，这个如RDF/OWL的Turtle、JSON序列化，如属性图的图数据库存储，结构化数据，非结构化数据的融合存储等

知识推理主要包括对前面获取的知识按照规则，逻辑描述等进行补全，也可以进行一些异常关系的检验等基本推理。此步一般可挖掘出一些简单的隐含知识。

知识计算此处我从知识推理中单独列出主要是强调一些深度关系挖掘等依赖图计算引擎如GraphX,Giraph才能实现的复杂计算处理。

以上简要描述了我们在做的系统及相关环节，知识图谱自2012年google新瓶装旧酒提出者概念后，在人工智能与大数据蓬勃发展的今天也迎来了春天，2018年全国知识图谱与语义计算大会召开，各种知识图谱名义的会议研讨会纷纷举行，中国计算机学会的计算机科学技术发展报告也重点讨论知识图谱技术在人工智能认知科学方面的研究进展。这无疑体现了知识图谱的趋势。如果错过了2016年的推荐元年，2017年的AI元年，请不要错过2018年的知识图谱元年。



## References



知识图谱历史简介及招聘 - 朱金华的文章 - 知乎 https://zhuanlan.zhihu.com/p/50239242

